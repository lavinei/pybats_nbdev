{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp point_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Forecasts\n",
    "\n",
    "> This module contains functions to find a specific point forecast from a forecast sample, which is a set of simulated values from the forecast distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#exporti\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This module assumes that samples come as 3-dimensional arrays. This is typical output from analysis function. The first dimension should have independent forecast samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# Optimal for MSE or mean squared error\n",
    "def mean(samps):\n",
    "    \"\"\"\n",
    "    Return the mean point forecasts, given samples from the analysis function.\n",
    "\n",
    "    This forecast is theoretically optimal for minimizing mean squared error loss.\n",
    "\n",
    "    :param samps: Forecast samples, returned from the analysis function. Will have 3-dimensions (nsamps * time * forecast horizon)\n",
    "    :return: Array of mean forecasts. Will have dimension (time * forecast horizon)\n",
    "    \"\"\"\n",
    "    return np.mean(samps, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# Optimal for MAD or absolute deviation\n",
    "def median(samps):\n",
    "    \"\"\"\n",
    "    Return the median point forecasts, given samples from the analysis function.\n",
    "\n",
    "    This forecast is theoretically optimal for minimizing mean absolute deviation loss.\n",
    "\n",
    "    :param samps: Forecast samples, returned from the analysis function. Will have 3-dimensions (nsamps * time * forecast horizon)\n",
    "    :return: Array of median forecasts. Will have dimension (time * forecast horizon)\n",
    "    \"\"\"\n",
    "    return np.median(samps, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# Utility function\n",
    "def weighted_quantile(samp, weights, quantile=0.5):\n",
    "    order = np.argsort(samp)\n",
    "    ord_samp = samp[order]\n",
    "    ord_weights = weights[order]\n",
    "    lower = ord_samp[np.max(np.where(np.cumsum(ord_weights) < quantile))]\n",
    "    upper = ord_samp[np.min(np.where(np.cumsum(ord_weights) > quantile))]\n",
    "    return np.round((upper + lower) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# Optimal for APE. Always less than the median. Ignores samples that are 0.\n",
    "def m_one_median(samps):\n",
    "    \"\"\"\n",
    "    Return the (-1)-median point forecasts, given samples from the analysis function.\n",
    "\n",
    "    This forecast is theoretically optimal for minimizing absolute percentage error loss.\n",
    "\n",
    "    :param samps: Forecast samples, returned from the analysis function. Will have 3-dimensions (nsamps * time * forecast horizon)\n",
    "    :return: Array of (-1)-median forecasts. Will have dimension (time * forecast horizon)\n",
    "    \"\"\"\n",
    "    def m_one_median(samp):\n",
    "        nz = samp.nonzero()[0]\n",
    "        weights = 1/samp[nz]\n",
    "        norm = np.sum(weights)\n",
    "        weights = weights/norm\n",
    "        if len(nz) < 5:\n",
    "            print('Less than 5 non-zero samples')\n",
    "        return weighted_quantile(samp[nz], weights)\n",
    "\n",
    "    forecast = np.apply_along_axis(m_one_median, 0, samps)\n",
    "\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# Here we get the joint one_median, where the rows are forecast samples\n",
    "# Assume that the forecast is 'joint' across the second dimension\n",
    "# This is optimal for the WAPE loss, where the denominator in the WAPE score is the sum over the second dimension\n",
    "# If the forecast samples are from a standard analysis function, that will be the sum over all forecast dates\n",
    "def joint_m_one_median(samps):\n",
    "\n",
    "    def joint_m_one_median(samp):\n",
    "        rows, cols = samp.shape\n",
    "        # Remove rows that are all zero\n",
    "        rowsums = np.sum(samp, axis=1)\n",
    "        psamp = samp[rowsums.nonzero()[0], :]\n",
    "        rowsums = rowsums[rowsums.nonzero()[0]]\n",
    "\n",
    "        # Weight each joint sample (i.e. row) by the inverse of its sum\n",
    "        weights = 1 / rowsums\n",
    "        norm = np.sum(weights)\n",
    "        weights = weights / norm\n",
    "\n",
    "        # Get the -1 median for each column using these joint weights\n",
    "        forecast = np.zeros(cols)\n",
    "        for c in range(cols):\n",
    "            forecast[c] = weighted_quantile(psamp[:, c], weights)\n",
    "\n",
    "        return forecast\n",
    "\n",
    "    if samps.ndim == 2:\n",
    "        return joint_m_one_median(samps)\n",
    "    elif samps.ndim == 3:\n",
    "        return np.array(list(map(joint_m_one_median, samps.transpose([1,0,2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# For the constrained point forecasts\n",
    "# F is a vector of constraints for the totals across the 3rd dimension of 'samps'\n",
    "# Expected dimensions are: nsamps x time x (forecast horizon or items)\n",
    "def constrained_mean(samps, F):\n",
    "    means = np.mean(samps, axis=0)\n",
    "    n = means.shape[1]\n",
    "    diff = (F - np.sum(means, axis=1))/n\n",
    "    return means + diff.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def constrained_median(samps, F):\n",
    "    if samps.ndim == 2:\n",
    "        samps = np.expand_dims(samps, axis=1)\n",
    "\n",
    "    # Initialize values\n",
    "    forecast = median(samps)\n",
    "    times = forecast.shape[0]\n",
    "    lambd = np.zeros(times)\n",
    "\n",
    "    # Iterate until a solution is found for each lambda\n",
    "    tol = 1\n",
    "    eps = 1E-2\n",
    "    max_shift = 5E-2\n",
    "    iter = 0\n",
    "    max_iter = 50\n",
    "    diff = F - np.sum(forecast, axis=1)\n",
    "    test = np.abs(diff) > tol\n",
    "\n",
    "    while np.any(test):\n",
    "        shift = np.abs(eps*diff)\n",
    "        shift[shift > max_shift] = max_shift\n",
    "        lambd = lambd + np.sign(diff)*shift\n",
    "        percentiles = 100*(1+lambd)/2\n",
    "        for idx, p in enumerate(percentiles):\n",
    "            if test[idx]:\n",
    "                forecast[idx,:] = np.percentile(samps[:,idx,:], p, axis=0, interpolation='nearest')\n",
    "        diff = F - np.sum(forecast, axis=1)\n",
    "        test = np.abs(diff) > tol\n",
    "        iter += 1\n",
    "        if iter > max_iter:\n",
    "           break\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def constrained_joint_m_one_median(samps, F):\n",
    "\n",
    "\n",
    "    def constrained_joint_m_one_median(samp, F):\n",
    "        #if samp.ndim == 2:\n",
    "        #    samp = np.expand_dims(samp, axis=1)\n",
    "\n",
    "        # Remove joint samples that are all 0\n",
    "        rowsums = np.sum(samp, axis=1)\n",
    "        nz = rowsums.nonzero()[0]\n",
    "        samp = samp[nz,:]\n",
    "        rowsums = rowsums[nz]\n",
    "        # Find weights\n",
    "        weights = 1 / rowsums\n",
    "        norm = np.sum(weights)\n",
    "        weights = weights / norm\n",
    "\n",
    "        # Initialize value\n",
    "        forecast = joint_m_one_median(samp).reshape(1,-1)\n",
    "        times = forecast.shape[0]\n",
    "        lambd = np.zeros(times)\n",
    "\n",
    "        # Iterate until a solution is found for each lambda\n",
    "        tol = 1\n",
    "        eps = 1E-2\n",
    "        max_shift = 5E-2\n",
    "        iter = 0\n",
    "        max_iter = 50\n",
    "        diff = F - np.sum(forecast)\n",
    "        test = np.abs(diff) > tol\n",
    "\n",
    "        while np.any(test):\n",
    "            shift = np.abs(eps * diff)\n",
    "            if shift > max_shift:\n",
    "                shift = max_shift\n",
    "            lambd = lambd + np.sign(diff) * shift\n",
    "            percentile = 100 * (1 + lambd) / 2\n",
    "            forecast = np.array(list(map(lambda s: weighted_quantile(s, weights, percentile/100),\n",
    "                                                 samp.T)))\n",
    "            diff = F - np.sum(forecast)\n",
    "            test = np.abs(diff) > tol\n",
    "            iter += 1\n",
    "            if iter > max_iter:\n",
    "                break\n",
    "        return forecast.reshape(1,-1)\n",
    "\n",
    "    if samps.ndim == 2:\n",
    "        samps = np.expand_dims(samps, axis=1)\n",
    "\n",
    "    return np.array(list(map(lambda samp, F: constrained_joint_m_one_median(samp, F),\n",
    "                             samps.transpose([1, 0, 2]),\n",
    "                             F)))[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "\n",
    "# Optimal for ZAPE. Always less than the (-1)-median.\n",
    "def zape_point_estimate(samps):\n",
    "    \"\"\"\n",
    "    Return the optimal point forecast for ZAPE loss, given samples from the analysis function.\n",
    "\n",
    "    This forecast is theoretically optimal for minimizing ZAPE loss, which is defined as:\n",
    "\n",
    "    .. math:: ZAPE(y, f) = \\\\frac{1}{n} \\sum_{i=1:n} I(y_i = 0) * f_i + I(y_i = 1) * |y_i-f_i| / y_i\n",
    "\n",
    "    :param samps: Forecast samples, returned from the analysis function. Will have 3-dimensions (nsamps * time * forecast horizon)\n",
    "    :return: Array of (-1)-median forecasts. Will have dimension (time * forecast horizon)\n",
    "    \"\"\"\n",
    "    def est_c_hat(samp):\n",
    "        nz = samp.nonzero()[0]\n",
    "        weights = 1/samp[nz]\n",
    "        c_hat = 1 / (1/len(nz) * np.sum(weights))\n",
    "        return c_hat\n",
    "\n",
    "    def zape_point_est(samp):\n",
    "        nz = samp.nonzero()[0]\n",
    "        pi_0 = len(nz) / len(samp) # probability of 0\n",
    "        weights = 1 / samp[nz]\n",
    "        norm = np.sum(weights)\n",
    "        weights = weights / norm\n",
    "        c_hat = est_c_hat(samp)\n",
    "        quantile = (1 - c_hat*pi_0)/2\n",
    "\n",
    "        return weighted_quantile(samp[nz], weights, quantile)\n",
    "\n",
    "    forecast = np.apply_along_axis(m_one_median, 0, samps)\n",
    "\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
