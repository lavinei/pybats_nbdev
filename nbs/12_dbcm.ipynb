{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dbcm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBCMs\n",
    "\n",
    "> The class DBCM, for a Dynamic Binary Cascade Model, which is the combination of a DCMM and a binary cascade, as described in [Berry, Helman, and West (2020)](https://arxiv.org/pdf/1808.04698.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DBCM is a combination of a Dynamic Count Mixture Model (DCMM) and a binary cascade of Bernoulli DGLMs. The original use case came from a retail sales settings. Consider a time series of both total transactions and sales for a single item. The DCMM is used to model the number of transactions that will involve an item. The binary cascade models the number of units that each shopper will purchase. The cascade is a sequence of probabilities for whether a shopper will purchase $r+1$ items, conditional on them having purchased $r$ items.\n",
    "\n",
    "The first component of a DBCM is the DCMM, used to model the total number of daily transactions containing the item of interest, $b_t$. We repeat the form of a DCMM for clarity:\n",
    "\n",
    "\\begin{equation} \\label{eqn-dcmm}\n",
    "z_t \\sim Ber(\\pi_t) \\text{ and } b_t \\mid z_t =\n",
    "\\begin{cases}\n",
    "0, & \\text{if } z_t = 0,\\\\\n",
    "1 + x_t, \\quad x_t \\sim Po(\\mu_t), & \\text{if }z_t = 1\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\pi_t$ and $\\mu_t$ vary according to the dynamics of independent Bernoulli and Poisson DGLMs respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transactions $b_t$ are related to sales by modeling the number of units sold in each transaction. Recognizing that sales outliers often occur due to shoppers buying many units of an item, the probability of each quantity is modeled with a binary cascade. Let $n_{r,t}$ be the number of transactions with more than $r$ units. Then $n_{r,t} | n_{r-1, t} \\sim Bin(n_{r-1,t}, \\pi_{r,t})$ is defined by a binomial DGLM. This cascade of binomial DGLMs represents the sequence of conditional probabilities for purchasing $r$ units or greater, given that the shopper has bought $r-1$. The sales $y_t$ are then:\n",
    "\n",
    "\\begin{equation}\\label{eqn-dbcm}\n",
    "y_t =\n",
    "\\begin{cases}\n",
    "0, & \\text{if } z_t = 0,\\\\\n",
    "\\sum_{r=1:d} r(n_{r-1, t} - n_{r,t}) + e_t, & \\text{if }z_t = 1,\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "where $d$ is the predefined length of the cascade and $e_t$ represents excess units greater than $d$. The cascade enables modeling of very small probabilities, in the rare cases when shoppers purchase large quantities of an item on a single grocery store trip.\n",
    "\n",
    "To model transactions with a quantity greater than $d$, we follow the \"Bayesian bootstrap\" strategy of [Berry, Helman, and West (2020)](https://arxiv.org/pdf/1808.04698.pdf), which is to record the observed outlier quantities purchased, and to forecast by sampling from the empirical distribution for the excess, $e_t$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#exporti\n",
    "from pybats_nbdev.dglm import bin_dglm\n",
    "from pybats_nbdev.dcmm import dcmm\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class dbcm:\n",
    "    def __init__(self,\n",
    "                 a0_bern = None,\n",
    "                 R0_bern = None,\n",
    "                 nregn_bern = 0,\n",
    "                 ntrend_bern = 0,\n",
    "                 nlf_bern = 0,\n",
    "                 nhol_bern = 0,\n",
    "                 seasPeriods_bern = [],\n",
    "                 seasHarmComponents_bern = [],\n",
    "                 deltrend_bern = 1, delregn_bern = 1,\n",
    "                 delhol_bern = 1, delseas_bern = 1,\n",
    "                 dellf_bern = 1,\n",
    "\n",
    "                 a0_pois = None,\n",
    "                 R0_pois = None,\n",
    "                 nregn_pois = 0,\n",
    "                 ntrend_pois = 0,\n",
    "                 nlf_pois = 0,\n",
    "                 nhol_pois = 0,\n",
    "                 seasPeriods_pois = [],\n",
    "                 seasHarmComponents_pois = [],\n",
    "                 deltrend_pois = 1, delregn_pois = 1,\n",
    "                 delhol_pois = 1, delseas_pois = 1,\n",
    "                 dellf_pois = 1,\n",
    "                 rho = 1,\n",
    "                 interpolate=True,\n",
    "                 adapt_discount=False,\n",
    "\n",
    "                 mod_dcmm = None,\n",
    "\n",
    "                 ncascade = 4,\n",
    "                 a0_cascade = None,  # List of length ncascade\n",
    "                 R0_cascade = None,  # List of length ncascade\n",
    "                 nregn_cascade = 0,\n",
    "                 ntrend_cascade = 0,\n",
    "                 nlf_cascade = 0,\n",
    "                 nhol_cascade = 0,\n",
    "                 seasPeriods_cascade = [],\n",
    "                 seasHarmComponents_cascade = [],\n",
    "                 deltrend_cascade = 1, delregn_cascade = 1,\n",
    "                 delhol_cascade = 1, delseas_cascade = 1,\n",
    "                 dellf_cascade = 1,\n",
    "\n",
    "                 excess = []):\n",
    "        \"\"\"\n",
    "\n",
    "        :param a0_bern: Prior mean vector for bernoulli DGLM\n",
    "        :param R0_bern: Prior covariance matrix for bernoulli DGLM\n",
    "        :param nregn_bern: Number of regression components in bernoulli DGLM\n",
    "        :param ntrend_bern: Number of trend components in bernoulli DGLM\n",
    "        :param nlf_bern: Number of latent factor components in bernoulli DGLM\n",
    "        :param seasPeriods_bern: List of periods of seasonal components in bernoulli DGLM\n",
    "        :param seasHarmComponents_bern: List of harmonic components included for each period in bernoulli DGLM\n",
    "        :param deltrend_bern: Discount factor on trend components in bernoulli DGLM\n",
    "        :param delregn_bern: Discount factor on regression components in bernoulli DGLM\n",
    "        :param delhol_bern: Discount factor on holiday component in bernoulli DGLM (currently deprecated)\n",
    "        :param delseas_bern: Discount factor on seasonal components in bernoulli DGLM\n",
    "        :param dellf_bern: Discount factor on latent factor components in bernoulli DGLM\n",
    "        :param a0_pois: Prior mean vector for poisson DGLM\n",
    "        :param R0_pois: Prior covariance matrix for poisson DGLM\n",
    "        :param nregn_pois: Number of regression components in poisson DGLM\n",
    "        :param ntrend_pois: Number of trend components in poisson DGLM\n",
    "        :param nlf_pois: Number of latent factor components in poisson DGLM\n",
    "        :param seasPeriods_pois: List of periods of seasonal components in poisson DGLM\n",
    "        :param seasHarmComponents_pois: List of harmonic components included for each period in poisson DGLM\n",
    "        :param deltrend_pois: Discount factor on trend components in poisson DGLM\n",
    "        :param delregn_pois: Discount factor on regression components in poisson DGLM\n",
    "        :param delhol_pois: Discount factor on holiday component in poisson DGLM (currently deprecated)\n",
    "        :param delseas_pois: Discount factor on seasonal components in poisson DGLM\n",
    "        :param dellf_pois: Discount factor on latent factor components in poisson DGLM\n",
    "        :param rho: Discount factor for random effects extension in poisson DGLM (smaller rho increases variance)\n",
    "        :param ncascade: Number of cascade components in binary cascade\n",
    "        :param a0_cascade: List of prior mean vectors for each binomial DGLM in cascade\n",
    "        :param R0_cascade: List of prior covariance vectors for each binomial DGLM in cascade\n",
    "        :param nregn_cascade: Number of regression components in each binomial DGLM in cascade\n",
    "        :param ntrend_cascade: Number of trend components in each binomial DGLM in cascade\n",
    "        :param nlf_cascade: Number of latent factor components in each binomial DGLM in cascade (not implemented yet)\n",
    "        :param seasPeriods_cascade: List of periods of seasonal components in each binomial DGLM in cascade\n",
    "        :param seasHarmComponents_cascade: List of harmonic components included for each period in each binomial DGLM in cascade\n",
    "        :param deltrend_cascade: Discount factor on trend components in each binomial DGLM in cascade\n",
    "        :param delregn_cascade: Discount factor on regression components in each binomial DGLM in cascade\n",
    "        :param delhol_cascade: Discount factor on holiday component in each binomial DGLM in cascade (currently deprecated)\n",
    "        :param delseas_cascade: Discount factor on seasonal components in each binomial DGLM in cascade\n",
    "        :param dellf_cascade: Discount factor on latent factor components in each binomial DGLM in cascade\n",
    "        :param excess: List of prior observed excess basket sizes >ncascade.\n",
    "        \"\"\"\n",
    "\n",
    "        if mod_dcmm is None:\n",
    "            self.dcmm = dcmm(a0_bern = a0_bern,\n",
    "                             R0_bern = R0_bern,\n",
    "                             nregn_bern=nregn_bern,\n",
    "                             ntrend_bern=ntrend_bern,\n",
    "                             nlf_bern=nlf_bern,\n",
    "                             nhol_bern=nhol_bern,\n",
    "                             seasPeriods_bern=seasPeriods_bern,\n",
    "                             seasHarmComponents_bern=seasHarmComponents_bern,\n",
    "                             deltrend_bern=deltrend_bern, delregn_bern=delregn_bern,\n",
    "                             delhol_bern=delhol_bern, delseas_bern=delseas_bern,\n",
    "                             dellf_bern=dellf_bern,\n",
    "\n",
    "                             a0_pois=a0_pois,\n",
    "                             R0_pois=R0_pois,\n",
    "                             nregn_pois=nregn_pois,\n",
    "                             ntrend_pois=ntrend_pois,\n",
    "                             nlf_pois=nlf_pois,\n",
    "                             nhol_pois=nhol_pois,\n",
    "                             seasPeriods_pois=seasPeriods_pois,\n",
    "                             seasHarmComponents_pois=seasHarmComponents_pois,\n",
    "                             deltrend_pois=deltrend_pois, delregn_pois=delregn_pois,\n",
    "                             delhol_pois=delhol_pois, delseas_pois=delseas_pois,\n",
    "                             dellf_pois=dellf_pois,\n",
    "                             rho = rho,\n",
    "                             interpolate=interpolate,\n",
    "                             adapt_discount=adapt_discount\n",
    "                             )\n",
    "        else:\n",
    "            self.dcmm = mod_dcmm\n",
    "\n",
    "        self.ncascade = ncascade\n",
    "        self.cascade = list(map(lambda a0, R0: bin_dglm(a0, R0,\n",
    "                                                        nregn = nregn_cascade,\n",
    "                                                        ntrend = ntrend_cascade,\n",
    "                                                        nlf= nlf_cascade,\n",
    "                                                        nhol = nhol_cascade,\n",
    "                                                        seasPeriods= seasPeriods_cascade,\n",
    "                                                        seasHarmComponents=seasHarmComponents_cascade,\n",
    "                                                        deltrend = deltrend_cascade,\n",
    "                                                        delregn = delregn_cascade,\n",
    "                                                        dellf = dellf_cascade,\n",
    "                                                        delhol = delhol_cascade,\n",
    "                                                        delseas = delseas_cascade,\n",
    "                                                        interpolate=interpolate,\n",
    "                                                        adapt_discount=adapt_discount),\n",
    "                                a0_cascade, R0_cascade))\n",
    "\n",
    "        self.t = 0\n",
    "\n",
    "        self.excess = excess\n",
    "\n",
    "    def update_cascade(self, y_transaction = None, y_cascade = None, X_cascade = None):\n",
    "        if y_cascade is None:\n",
    "            for i in range(self.ncascade):\n",
    "                self.cascade[i].update()\n",
    "        else:\n",
    "            # Update the cascade of binomial DGLMs for basket sizes\n",
    "            self.cascade[0].update(y_transaction, y_cascade[0], X_cascade)\n",
    "            for i in range(1, self.ncascade):\n",
    "                self.cascade[i].update(y_cascade[i - 1], y_cascade[i], X_cascade)\n",
    "\n",
    "    def forecast_cascade(self, k, transaction_samps, X_cascade = None, nsamps = 1, mean_only=False):\n",
    "        # forecast the sales from a cascade\n",
    "        if mean_only:\n",
    "            nsamps=1\n",
    "\n",
    "        cascade_samps = np.zeros([self.ncascade, nsamps])\n",
    "        cascade_samps[0, :] = self.cascade[0].forecast_marginal(transaction_samps, k, X_cascade, nsamps, mean_only)\n",
    "        for i in range(1, self.ncascade):\n",
    "            cascade_samps[i, :] = self.cascade[i].forecast_marginal(cascade_samps[i - 1, :], k, X_cascade, nsamps, mean_only)\n",
    "\n",
    "        return cascade_samps\n",
    "\n",
    "    def forecast_excess(self, max_cascade_samps, nsamps, mean_only=False):\n",
    "\n",
    "        if mean_only:\n",
    "            if len(self.excess) == 0:\n",
    "                return np.array([(1)*max_cascade_samps]).reshape(1,1)\n",
    "            else:\n",
    "                return np.array([(np.mean(self.excess) - self.ncascade)*max_cascade_samps]).reshape(1,1)\n",
    "\n",
    "        excess_samps = np.zeros([1, nsamps])\n",
    "        sample = partial(np.random.choice, a=self.excess, replace=True)\n",
    "        # If we have no prior data of any excess purchases, just assume the basket size\n",
    "        # Is 1 greater than the last cascade we have in the model\n",
    "        if len(self.excess) == 0:\n",
    "            for idx in np.nonzero(max_cascade_samps)[0]:\n",
    "                excess_samps[0, idx] = max_cascade_samps[idx] * 1\n",
    "        else:\n",
    "            for idx in np.nonzero(max_cascade_samps)[0]:\n",
    "                excess_samps[0, idx] = np.sum(sample(size = max_cascade_samps[idx].astype(int))) - max_cascade_samps[idx] * self.ncascade\n",
    "\n",
    "        return excess_samps\n",
    "\n",
    "    # X is a list or tuple of length 3.\n",
    "    # Data for the bernoulli DGLM, the Poisson DGLM, and then the cascade\n",
    "    # Note we assume that all binomials in the cascade have the same regression components\n",
    "    def update(self, y_transaction = None, X_transaction = None, y_cascade = None, X_cascade = None, excess = []):\n",
    "        # Update the DCMM for transactions\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     self.dcmm.update(y_transaction, (X_transaction[0], X_transaction[1]))\n",
    "        # else:\n",
    "        #     self.dcmm.update(y_transaction, (X_transaction, X_transaction))\n",
    "\n",
    "        self.dcmm.update(y_transaction, X_transaction)\n",
    "\n",
    "        self.update_cascade(y_transaction, y_cascade, X_cascade)\n",
    "        # If there were any excess transactions, add that to the excess list\n",
    "        self.excess.extend(excess)\n",
    "        self.t += 1\n",
    "\n",
    "    # Note we assume that the cascade has no latent factors, only the DCMM for transactions\n",
    "    def update_lf_sample(self, y_transaction = None, X_transaction = None, y_cascade = None, X_cascade = None, phi_samps = None, excess = []):\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     self.dcmm.update_lf_sample(y_transaction, (X_transaction[0], X_transaction[1]), (phi_samps, phi_samps))\n",
    "        # else:\n",
    "        #     self.dcmm.update_lf_sample(y_transaction, (X_transaction, X_transaction), (phi_samps, phi_samps))\n",
    "\n",
    "        self.dcmm.update_lf_sample(y_transaction, X_transaction, (phi_samps, phi_samps))\n",
    "        self.update_cascade(y_transaction, y_cascade, X_cascade)\n",
    "        self.excess.extend(excess)\n",
    "        self.t += 1\n",
    "\n",
    "    def update_lf_analytic(self, y_transaction = None, X_transaction = None, y_cascade = None, X_cascade = None, phi_mu = None, phi_sigma = None, excess = []):\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "        # pm = self.make_pair(phi_mu)\n",
    "        # ps = self.make_pair(phi_sigma)\n",
    "\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     self.dcmm.update_lf_analytic(y_transaction,\n",
    "        #                                        (X_transaction[0], X_transaction[1]),\n",
    "        #                                        (phi_mu, phi_mu),\n",
    "        #                                        (phi_sigma, phi_sigma))\n",
    "        # else:\n",
    "        #     self.dcmm.update_lf_analytic(y_transaction,\n",
    "        #                                        (X_transaction, X_transaction),\n",
    "        #                                        (phi_mu, phi_mu),\n",
    "        #                                        (phi_sigma, phi_sigma))\n",
    "\n",
    "        self.dcmm.update_lf_analytic(y_transaction,\n",
    "                                     X_transaction,\n",
    "                                     phi_mu,\n",
    "                                     phi_sigma)\n",
    "        self.update_cascade(y_transaction, y_cascade, X_cascade)\n",
    "\n",
    "        self.excess.extend(excess)\n",
    "\n",
    "        self.t += 1\n",
    "\n",
    "    def forecast_marginal(self, k, X_transaction = None, X_cascade = None, nsamps = 1, mean_only = False, return_separate = False, **kwargs):\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     transaction_samps = self.dcmm.forecast_marginal(k, (X_transaction[0], X_transaction[1]), nsamps, mean_only)\n",
    "        # else:\n",
    "        #     transaction_samps = self.dcmm.forecast_marginal(k, (X_transaction, X_transaction), nsamps, mean_only)\n",
    "\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "\n",
    "        transaction_samps = self.dcmm.forecast_marginal(k, X_transaction, nsamps, mean_only)\n",
    "        cascade_samps = self.forecast_cascade(k, transaction_samps, X_cascade, nsamps, mean_only)\n",
    "        excess_samps = self.forecast_excess(cascade_samps[self.ncascade-1,:], nsamps, mean_only)\n",
    "\n",
    "        # Sometimes we may want to investigate the transaction, cascade, and excess samples separately\n",
    "        if return_separate:\n",
    "            return transaction_samps, cascade_samps, excess_samps\n",
    "\n",
    "        samps = np.r_[transaction_samps.reshape(1, -1), cascade_samps, excess_samps.reshape(1, -1)]\n",
    "        return np.sum(samps, axis = 0)\n",
    "\n",
    "    def forecast_marginal_lf_sample(self, k, X_transaction = None, X_cascade = None, phi_samps = None, nsamps = 1, mean_only = False, return_separate = False, **kwargs):\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     transaction_samps = self.dcmm.forecast_marginal_lf_sample(k, (X_transaction[0], X_transaction[1]),\n",
    "        #                                                                (phi_samps, phi_samps), nsamps, mean_only)\n",
    "        # else:\n",
    "        #     transaction_samps = self.dcmm.forecast_marginal_lf_sample(k, (X_transaction, X_transaction), (phi_samps, phi_samps), nsamps, mean_only)\n",
    "\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "        transaction_samps = self.dcmm.forecast_marginal_lf_sample(k, X_transaction,\n",
    "                                                                  (phi_samps, phi_samps), nsamps, mean_only)\n",
    "        cascade_samps = self.forecast_cascade(k, transaction_samps, X_cascade, nsamps, mean_only)\n",
    "        excess_samps = self.forecast_excess(cascade_samps[self.ncascade-1, :], nsamps, mean_only)\n",
    "\n",
    "        # Sometimes we may want to investigate the transaction, cascade, and excess samples separately\n",
    "        if return_separate:\n",
    "            return transaction_samps, cascade_samps, excess_samps\n",
    "\n",
    "        samps = np.r_[transaction_samps.reshape(1,-1), cascade_samps, excess_samps.reshape(1,-1)]\n",
    "        return np.sum(samps, axis=0)\n",
    "\n",
    "    def forecast_marginal_lf_analytic(self, k, X_transaction = None, X_cascade = None, phi_mu = None, phi_sigma = None, nsamps = 1, mean_only = False, return_separate=False, **kwargs):\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     transaction_samps = self.dcmm.forecast_marginal_lf_analytic(k, (X_transaction[0], X_transaction[1]),\n",
    "        #                                                                       (phi_mu, phi_mu), (phi_sigma, phi_sigma),\n",
    "        #                                                                       nsamps, mean_only)\n",
    "        # else:\n",
    "        #     transaction_samps = self.dcmm.forecast_marginal_lf_analytic(k, (X_transaction, X_transaction), (phi_mu, phi_mu), (phi_sigma, phi_sigma), nsamps, mean_only)\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "        # pm = self.make_pair(phi_mu)\n",
    "        # ps = self.make_pair(phi_sigma)\n",
    "\n",
    "        transaction_samps = self.dcmm.forecast_marginal_lf_analytic(k, X_transaction, phi_mu, phi_sigma, nsamps, mean_only)\n",
    "        cascade_samps = self.forecast_cascade(k, transaction_samps, X_cascade, nsamps, mean_only)\n",
    "        excess_samps = self.forecast_excess(cascade_samps[self.ncascade-1, :], nsamps, mean_only)\n",
    "\n",
    "        # Sometimes we may want to investigate the transaction, cascade, and excess samples separately\n",
    "        if return_separate:\n",
    "            return transaction_samps, cascade_samps, excess_samps\n",
    "\n",
    "        samps = np.r_[transaction_samps.reshape(1,-1), cascade_samps, excess_samps.reshape(1,-1)]\n",
    "        return np.sum(samps, axis=0)\n",
    "\n",
    "    def forecast_path(self, k, X_transaction = None, X_cascade = None, nsamps = 1, return_separate = False):\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     transaction_samps = self.dcmm.forecast_path(k, (X_transaction[0], X_transaction[1]), nsamps)\n",
    "        # else:\n",
    "        #     transaction_samps = self.dcmm.forecast_path(k, (X_transaction, X_transaction), nsamps)\n",
    "\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "\n",
    "        transaction_samps = self.dcmm.forecast_path(k, X_transaction, nsamps)\n",
    "        cascade_samps = np.array(\n",
    "            list(map(lambda h: self.forecast_cascade(h, transaction_samps[:, h], X_cascade[h], nsamps),\n",
    "                     range(k)))).T\n",
    "        excess_samps = np.array(list(map(lambda h: self.forecast_excess(cascade_samps[:, self.ncascade-1, h], nsamps),\n",
    "                     range(k)))).T\n",
    "\n",
    "        # Sometimes we may want to investigate the transaction, cascade, and excess samples separately\n",
    "        if return_separate:\n",
    "            return transaction_samps, cascade_samps, excess_samps\n",
    "\n",
    "\n",
    "        samps = np.concatenate((transaction_samps[:, None, :], cascade_samps, excess_samps), axis=1)\n",
    "        return np.sum(samps, axis=1)\n",
    "\n",
    "    def forecast_path_copula(self, k, X_transaction = None, X_cascade = None, nsamps = 1, return_separate = False, **kwargs):\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     transaction_samps = self.dcmm.forecast_path_copula(k, (X_transaction[0], X_transaction[1]), nsamps, **kwargs)\n",
    "        # else:\n",
    "        #     transaction_samps = self.dcmm.forecast_path_copula(k, (X_transaction, X_transaction), nsamps, **kwargs)\n",
    "\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "\n",
    "        transaction_samps = self.dcmm.forecast_path_copula(k, X_transaction, nsamps, **kwargs)\n",
    "        cascade_samps = np.array(\n",
    "            list(map(lambda h: self.forecast_cascade(h, transaction_samps[:, h], X_cascade[h], nsamps),\n",
    "                     range(k)))).T\n",
    "        excess_samps = np.array(list(map(lambda h: self.forecast_excess(cascade_samps[:, self.ncascade-1, h], nsamps),\n",
    "                                         range(k)))).T\n",
    "\n",
    "        # Sometimes we may want to investigate the transaction, cascade, and excess samples separately\n",
    "        if return_separate:\n",
    "            return transaction_samps, cascade_samps, excess_samps\n",
    "\n",
    "        samps = np.concatenate((transaction_samps[:, None, :], cascade_samps, excess_samps), axis=1)\n",
    "        return np.sum(samps, axis=1)\n",
    "\n",
    "    def forecast_path_lf_copula(self, k, X_transaction = None, X_cascade = None, phi_mu = None, phi_sigma = None, phi_psi = None, nsamps = 1, return_separate = False, **kwargs):\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     transaction_samps = self.dcmm.forecast_path_lf_copula(k, (X_transaction[0], X_transaction[1]),\n",
    "        #                                                                   (phi_mu, phi_mu), (phi_sigma, phi_sigma),\n",
    "        #                                                                   (phi_psi, phi_psi), nsamps, **kwargs)\n",
    "        # else:\n",
    "        #     transaction_samps = self.dcmm.forecast_path_lf_copula(k, (X_transaction, X_transaction), (phi_mu, phi_mu), (phi_sigma, phi_sigma), (phi_psi, phi_psi), nsamps, **kwargs)\n",
    "\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "        # pm = self.make_pair(phi_mu)\n",
    "        # ps = self.make_pair(phi_sigma)\n",
    "        # pp = self.make_pair(phi_psi)\n",
    "\n",
    "        transaction_samps = self.dcmm.forecast_path_lf_copula(k, X_transaction, phi_mu, phi_sigma, phi_psi, nsamps, **kwargs)\n",
    "        cascade_samps = np.array(\n",
    "            list(map(lambda h: self.forecast_cascade(h, transaction_samps[:, h], X_cascade[h], nsamps),\n",
    "                     range(k)))).T\n",
    "        excess_samps = np.array(list(map(lambda h: self.forecast_excess(cascade_samps[:, self.ncascade-1, h], nsamps),\n",
    "                                         range(k)))).T\n",
    "\n",
    "        # Sometimes we may want to investigate the transaction, cascade, and excess samples separately\n",
    "        if return_separate:\n",
    "            return transaction_samps, cascade_samps, excess_samps\n",
    "\n",
    "        samps = np.concatenate((transaction_samps[:, None, :], cascade_samps, excess_samps), axis=1)\n",
    "        return np.sum(samps, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DBCM can be used in the same way as a DGLM, with the standard methods `dbcm.update`, `dbcm.forecast_marginal`, and `dbcm.forecast_path`. There are equivalent helper functions as well. A full analysis can be run with `analysis_dbcm`, and `define_dbcm` helps to initialize a DBCM.\n",
    "\n",
    "A quick example of using `analysis_dbcm` follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pybats_nbdev.shared import load_dbcm_latent_factor_example\n",
    "from pybats_nbdev.analysis import analysis_dbcm\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "data = load_dbcm_latent_factor_example()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>Y_transaction</th>\n",
       "      <th>X_transaction</th>\n",
       "      <th>mt1</th>\n",
       "      <th>mt2</th>\n",
       "      <th>mt3</th>\n",
       "      <th>mt4</th>\n",
       "      <th>X_cascade</th>\n",
       "      <th>excess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-06-01</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.376729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-02</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.797680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-03</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.687661</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-04</th>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.188624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-05</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.684483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales  Y_transaction  X_transaction  mt1  mt2  mt3  mt4  \\\n",
       "2014-06-01    7.0            6.0       0.376729  1.0  0.0  0.0  0.0   \n",
       "2014-06-02    3.0            3.0       1.797680  0.0  0.0  0.0  0.0   \n",
       "2014-06-03    9.0            7.0      -1.687661  2.0  0.0  0.0  0.0   \n",
       "2014-06-04   11.0           10.0      -0.188624  1.0  0.0  0.0  0.0   \n",
       "2014-06-05    5.0            4.0       0.684483  1.0  0.0  0.0  0.0   \n",
       "\n",
       "            X_cascade excess  \n",
       "2014-06-01          0     []  \n",
       "2014-06-02          1     []  \n",
       "2014-06-03          1     []  \n",
       "2014-06-04          0     []  \n",
       "2014-06-05          1     []  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has already been formatted for use in a DBCM:\n",
    "\n",
    "- `Sales` are the final outcome we want to model. \n",
    "- `Y_transaction` is the number of transactions, which is always less than or equal to the total `Sales`.\n",
    "- `X_transaction` is a predictor variable - item price - for total transactions.\n",
    "- `mt1` through `mt4` is the number of shoppers who purchased *more than r* units of the item.\n",
    "- `X_cascade` is an indicator of item promotions - such as \"buy one get one free\" - which would influence the quantity each shopper buys. \n",
    "- `excess` is a list of unit quantities for any shoppers with 5 or more items in their cart, which extends beyond the length of the cascade, which is set to the default of $4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = .2\n",
    "k = 14\n",
    "nsamps = 200\n",
    "prior_length = 21\n",
    "\n",
    "dates = data.index\n",
    "forecast_start_date = dates[-100]\n",
    "forecast_end_date = dates[-50]\n",
    "data = data[:forecast_end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning forecasting\n"
     ]
    }
   ],
   "source": [
    "mod, forecast_samples = analysis_dbcm(data['Y_transaction'].values.reshape(-1),\n",
    "                                 data['X_transaction'].values.reshape(-1,1), \n",
    "                                 data[['mt1', 'mt2', 'mt3', 'mt4']].values,\n",
    "                                 data['X_cascade'].values.reshape(-1,1),\n",
    "                                 data['excess'].values,\n",
    "                                 prior_length=prior_length,\n",
    "                                 k=k, forecast_start=forecast_start_date, forecast_end=forecast_end_date,\n",
    "                                 nsamps=nsamps, rho=rho,\n",
    "                                 dates = dates, delregn_pois=.98,\n",
    "                                     ret=['model', 'forecast'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DBCM is a wrapper for the DCMM and the binary cascade. To illustrate, we can use the mod.forecast_marginal, with two flags activated:\n",
    "- `mean_only=True`, which is available for all models in PyBATS. Returns the mean of the forecast distribution, instead of samples.\n",
    "- `return_separate=True`, available only for DBCMs. This divides the forecast into the transaction, binary cascade, and excess, returning each separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_mean, cascade_mean, excess_mean = \\\n",
    "mod.forecast_marginal(k=1,\n",
    "                      X_transaction=data['X_transaction'].values[-1],\n",
    "                      X_cascade = data['X_cascade'].values[-1],\n",
    "                      mean_only=True,\n",
    "                      return_separate=True)\n",
    "\n",
    "out = {'transaction_mean':transaction_mean, 'mt1':cascade_mean[0],\n",
    "      'mt2':cascade_mean[1], }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dglm.ipynb.\n",
      "Converted 01_update.ipynb.\n",
      "Converted 02_forecast.ipynb.\n",
      "Converted 03_define_models.ipynb.\n",
      "Converted 04_seasonal.ipynb.\n",
      "Converted 05_analysis.ipynb.\n",
      "Converted 06_conjugates.ipynb.\n",
      "Converted 07_point_forecast.ipynb.\n",
      "Converted 08_loss_functions.ipynb.\n",
      "Converted 09_plot.ipynb.\n",
      "Converted 10_shared.ipynb.\n",
      "Converted 11_dcmm.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
