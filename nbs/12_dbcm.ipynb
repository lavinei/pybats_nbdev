{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dbcm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dbcm\n",
    "\n",
    "> This module contains the class for the Dynamic Binary Cascade Model (DBCM), as described in Berry and West (2020) INSERT LINK.\n",
    "\n",
    "The DBCM is a combination of a DCMM and a binary cascade of Bernoulli DGLMs. The original use case come from a retail setting. Consider a time series of both transactions and sales for a single item. The DCMM is used to model the number of transactions that will involve an item. The binary cascade is used to model the number of units of the item that will be sold. In this setting it makes sense to use particular sales information - such as a 'Buy One Get One Free' - promotion, which will encourage shoppers to buy 2 units of an item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#exporti\n",
    "from pybats_nbdev.dglm import bin_dglm\n",
    "from pybats_nbdev.dcmm import dcmm\n",
    "from functools import partial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class DBCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class dbcm:\n",
    "    def __init__(self,\n",
    "                 a0_bern = None,\n",
    "                 R0_bern = None,\n",
    "                 nregn_bern = 0,\n",
    "                 ntrend_bern = 0,\n",
    "                 nlf_bern = 0,\n",
    "                 nhol_bern = 0,\n",
    "                 seasPeriods_bern = [],\n",
    "                 seasHarmComponents_bern = [],\n",
    "                 deltrend_bern = 1, delregn_bern = 1,\n",
    "                 delhol_bern = 1, delseas_bern = 1,\n",
    "                 dellf_bern = 1,\n",
    "\n",
    "                 a0_pois = None,\n",
    "                 R0_pois = None,\n",
    "                 nregn_pois = 0,\n",
    "                 ntrend_pois = 0,\n",
    "                 nlf_pois = 0,\n",
    "                 nhol_pois = 0,\n",
    "                 seasPeriods_pois = [],\n",
    "                 seasHarmComponents_pois = [],\n",
    "                 deltrend_pois = 1, delregn_pois = 1,\n",
    "                 delhol_pois = 1, delseas_pois = 1,\n",
    "                 dellf_pois = 1,\n",
    "                 rho = 1,\n",
    "                 interpolate=True,\n",
    "                 adapt_discount=False,\n",
    "\n",
    "                 mod_dcmm = None,\n",
    "\n",
    "                 ncascade = 4,\n",
    "                 a0_cascade = None,  # List of length ncascade\n",
    "                 R0_cascade = None,  # List of length ncascade\n",
    "                 nregn_cascade = 0,\n",
    "                 ntrend_cascade = 0,\n",
    "                 nlf_cascade = 0,\n",
    "                 nhol_cascade = 0,\n",
    "                 seasPeriods_cascade = [],\n",
    "                 seasHarmComponents_cascade = [],\n",
    "                 deltrend_cascade = 1, delregn_cascade = 1,\n",
    "                 delhol_cascade = 1, delseas_cascade = 1,\n",
    "                 dellf_cascade = 1,\n",
    "\n",
    "                 excess = []):\n",
    "        \"\"\"\n",
    "\n",
    "        :param a0_bern: Prior mean vector for bernoulli DGLM\n",
    "        :param R0_bern: Prior covariance matrix for bernoulli DGLM\n",
    "        :param nregn_bern: Number of regression components in bernoulli DGLM\n",
    "        :param ntrend_bern: Number of trend components in bernoulli DGLM\n",
    "        :param nlf_bern: Number of latent factor components in bernoulli DGLM\n",
    "        :param seasPeriods_bern: List of periods of seasonal components in bernoulli DGLM\n",
    "        :param seasHarmComponents_bern: List of harmonic components included for each period in bernoulli DGLM\n",
    "        :param deltrend_bern: Discount factor on trend components in bernoulli DGLM\n",
    "        :param delregn_bern: Discount factor on regression components in bernoulli DGLM\n",
    "        :param delhol_bern: Discount factor on holiday component in bernoulli DGLM (currently deprecated)\n",
    "        :param delseas_bern: Discount factor on seasonal components in bernoulli DGLM\n",
    "        :param dellf_bern: Discount factor on latent factor components in bernoulli DGLM\n",
    "        :param a0_pois: Prior mean vector for poisson DGLM\n",
    "        :param R0_pois: Prior covariance matrix for poisson DGLM\n",
    "        :param nregn_pois: Number of regression components in poisson DGLM\n",
    "        :param ntrend_pois: Number of trend components in poisson DGLM\n",
    "        :param nlf_pois: Number of latent factor components in poisson DGLM\n",
    "        :param seasPeriods_pois: List of periods of seasonal components in poisson DGLM\n",
    "        :param seasHarmComponents_pois: List of harmonic components included for each period in poisson DGLM\n",
    "        :param deltrend_pois: Discount factor on trend components in poisson DGLM\n",
    "        :param delregn_pois: Discount factor on regression components in poisson DGLM\n",
    "        :param delhol_pois: Discount factor on holiday component in poisson DGLM (currently deprecated)\n",
    "        :param delseas_pois: Discount factor on seasonal components in poisson DGLM\n",
    "        :param dellf_pois: Discount factor on latent factor components in poisson DGLM\n",
    "        :param rho: Discount factor for random effects extension in poisson DGLM (smaller rho increases variance)\n",
    "        :param ncascade: Number of cascade components in binary cascade\n",
    "        :param a0_cascade: List of prior mean vectors for each binomial DGLM in cascade\n",
    "        :param R0_cascade: List of prior covariance vectors for each binomial DGLM in cascade\n",
    "        :param nregn_cascade: Number of regression components in each binomial DGLM in cascade\n",
    "        :param ntrend_cascade: Number of trend components in each binomial DGLM in cascade\n",
    "        :param nlf_cascade: Number of latent factor components in each binomial DGLM in cascade (not implemented yet)\n",
    "        :param seasPeriods_cascade: List of periods of seasonal components in each binomial DGLM in cascade\n",
    "        :param seasHarmComponents_cascade: List of harmonic components included for each period in each binomial DGLM in cascade\n",
    "        :param deltrend_cascade: Discount factor on trend components in each binomial DGLM in cascade\n",
    "        :param delregn_cascade: Discount factor on regression components in each binomial DGLM in cascade\n",
    "        :param delhol_cascade: Discount factor on holiday component in each binomial DGLM in cascade (currently deprecated)\n",
    "        :param delseas_cascade: Discount factor on seasonal components in each binomial DGLM in cascade\n",
    "        :param dellf_cascade: Discount factor on latent factor components in each binomial DGLM in cascade\n",
    "        :param excess: List of prior observed excess basket sizes >ncascade.\n",
    "        \"\"\"\n",
    "\n",
    "        if mod_dcmm is None:\n",
    "            self.dcmm = dcmm(a0_bern = a0_bern,\n",
    "                             R0_bern = R0_bern,\n",
    "                             nregn_bern=nregn_bern,\n",
    "                             ntrend_bern=ntrend_bern,\n",
    "                             nlf_bern=nlf_bern,\n",
    "                             nhol_bern=nhol_bern,\n",
    "                             seasPeriods_bern=seasPeriods_bern,\n",
    "                             seasHarmComponents_bern=seasHarmComponents_bern,\n",
    "                             deltrend_bern=deltrend_bern, delregn_bern=delregn_bern,\n",
    "                             delhol_bern=delhol_bern, delseas_bern=delseas_bern,\n",
    "                             dellf_bern=dellf_bern,\n",
    "\n",
    "                             a0_pois=a0_pois,\n",
    "                             R0_pois=R0_pois,\n",
    "                             nregn_pois=nregn_pois,\n",
    "                             ntrend_pois=ntrend_pois,\n",
    "                             nlf_pois=nlf_pois,\n",
    "                             nhol_pois=nhol_pois,\n",
    "                             seasPeriods_pois=seasPeriods_pois,\n",
    "                             seasHarmComponents_pois=seasHarmComponents_pois,\n",
    "                             deltrend_pois=deltrend_pois, delregn_pois=delregn_pois,\n",
    "                             delhol_pois=delhol_pois, delseas_pois=delseas_pois,\n",
    "                             dellf_pois=dellf_pois,\n",
    "                             rho = rho,\n",
    "                             interpolate=interpolate,\n",
    "                             adapt_discount=adapt_discount\n",
    "                             )\n",
    "        else:\n",
    "            self.dcmm = mod_dcmm\n",
    "        \n",
    "        self.ncascade = ncascade\n",
    "        self.cascade = list(map(lambda a0, R0: bin_dglm(a0, R0,\n",
    "                                                        nregn = nregn_cascade,\n",
    "                                                        ntrend = ntrend_cascade,\n",
    "                                                        nlf= nlf_cascade,\n",
    "                                                        nhol = nhol_cascade,\n",
    "                                                        seasPeriods= seasPeriods_cascade,\n",
    "                                                        seasHarmComponents=seasHarmComponents_cascade,\n",
    "                                                        deltrend = deltrend_cascade,\n",
    "                                                        delregn = delregn_cascade,\n",
    "                                                        dellf = dellf_cascade,\n",
    "                                                        delhol = delhol_cascade,\n",
    "                                                        delseas = delseas_cascade,\n",
    "                                                        interpolate=interpolate,\n",
    "                                                        adapt_discount=adapt_discount),\n",
    "                                a0_cascade, R0_cascade))\n",
    "        \n",
    "        self.t = 0\n",
    "\n",
    "        self.excess = excess\n",
    "\n",
    "    def update_cascade(self, y_transaction = None, y_cascade = None, X_cascade = None):\n",
    "        if y_cascade is None:\n",
    "            for i in range(self.ncascade):\n",
    "                self.cascade[i].update()\n",
    "        else:\n",
    "            # Update the cascade of binomial DGLMs for basket sizes\n",
    "            self.cascade[0].update(y_transaction, y_cascade[0], X_cascade)\n",
    "            for i in range(1, self.ncascade):\n",
    "                self.cascade[i].update(y_cascade[i - 1], y_cascade[i], X_cascade)\n",
    "\n",
    "    def forecast_cascade(self, k, transaction_samps, X_cascade = None, nsamps = 1, mean_only=False):\n",
    "        # forecast the sales from a cascade\n",
    "        if mean_only:\n",
    "            nsamps=1\n",
    "\n",
    "        cascade_samps = np.zeros([self.ncascade, nsamps])\n",
    "        cascade_samps[0, :] = self.cascade[0].forecast_marginal(transaction_samps, k, X_cascade, nsamps, mean_only)\n",
    "        for i in range(1, self.ncascade):\n",
    "            cascade_samps[i, :] = self.cascade[i].forecast_marginal(cascade_samps[i - 1, :], k, X_cascade, nsamps, mean_only)\n",
    "\n",
    "        return cascade_samps\n",
    "\n",
    "    def forecast_excess(self, max_cascade_samps, nsamps, mean_only=False):\n",
    "\n",
    "        if mean_only:\n",
    "            if len(self.excess) == 0:\n",
    "                return np.array([(1)*max_cascade_samps]).reshape(1,1)\n",
    "            else:\n",
    "                return np.array([(np.mean(self.excess) - self.ncascade)*max_cascade_samps]).reshape(1,1)\n",
    "\n",
    "        excess_samps = np.zeros([1, nsamps])\n",
    "        sample = partial(np.random.choice, a=self.excess, replace=True)\n",
    "        # If we have no prior data of any excess purchases, just assume the basket size\n",
    "        # Is 1 greater than the last cascade we have in the model\n",
    "        if len(self.excess) == 0:\n",
    "            for idx in np.nonzero(max_cascade_samps)[0]:\n",
    "                excess_samps[0, idx] = max_cascade_samps[idx] * 1\n",
    "        else:\n",
    "            for idx in np.nonzero(max_cascade_samps)[0]:\n",
    "                excess_samps[0, idx] = np.sum(sample(size = max_cascade_samps[idx].astype(int))) - max_cascade_samps[idx] * self.ncascade\n",
    "\n",
    "        return excess_samps\n",
    "\n",
    "    # X is a list or tuple of length 3.\n",
    "    # Data for the bernoulli DGLM, the Poisson DGLM, and then the cascade\n",
    "    # Note we assume that all binomials in the cascade have the same regression components\n",
    "    def update(self, y_transaction = None, X_transaction = None, y_cascade = None, X_cascade = None, excess = []):\n",
    "        # Update the DCMM for transactions\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     self.dcmm.update(y_transaction, (X_transaction[0], X_transaction[1]))\n",
    "        # else:\n",
    "        #     self.dcmm.update(y_transaction, (X_transaction, X_transaction))\n",
    "\n",
    "        self.dcmm.update(y_transaction, X_transaction)\n",
    "\n",
    "        self.update_cascade(y_transaction, y_cascade, X_cascade)\n",
    "        # If there were any excess transactions, add that to the excess list\n",
    "        self.excess.extend(excess)\n",
    "        self.t += 1\n",
    "        \n",
    "    # Note we assume that the cascade has no latent factors, only the DCMM for transactions\n",
    "    def update_lf_sample(self, y_transaction = None, X_transaction = None, y_cascade = None, X_cascade = None, phi_samps = None, excess = []):\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     self.dcmm.update_lf_sample(y_transaction, (X_transaction[0], X_transaction[1]), (phi_samps, phi_samps))\n",
    "        # else:\n",
    "        #     self.dcmm.update_lf_sample(y_transaction, (X_transaction, X_transaction), (phi_samps, phi_samps))\n",
    "\n",
    "        self.dcmm.update_lf_sample(y_transaction, X_transaction, (phi_samps, phi_samps))\n",
    "        self.update_cascade(y_transaction, y_cascade, X_cascade)\n",
    "        self.excess.extend(excess)\n",
    "        self.t += 1\n",
    "\n",
    "    def update_lf_analytic(self, y_transaction = None, X_transaction = None, y_cascade = None, X_cascade = None, phi_mu = None, phi_sigma = None, excess = []):\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "        # pm = self.make_pair(phi_mu)\n",
    "        # ps = self.make_pair(phi_sigma)\n",
    "\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     self.dcmm.update_lf_analytic(y_transaction,\n",
    "        #                                        (X_transaction[0], X_transaction[1]),\n",
    "        #                                        (phi_mu, phi_mu),\n",
    "        #                                        (phi_sigma, phi_sigma))\n",
    "        # else:\n",
    "        #     self.dcmm.update_lf_analytic(y_transaction,\n",
    "        #                                        (X_transaction, X_transaction),\n",
    "        #                                        (phi_mu, phi_mu),\n",
    "        #                                        (phi_sigma, phi_sigma))\n",
    "\n",
    "        self.dcmm.update_lf_analytic(y_transaction,\n",
    "                                     X_transaction,\n",
    "                                     phi_mu,\n",
    "                                     phi_sigma)\n",
    "        self.update_cascade(y_transaction, y_cascade, X_cascade)\n",
    "\n",
    "        self.excess.extend(excess)\n",
    "                \n",
    "        self.t += 1\n",
    "\n",
    "    def forecast_marginal(self, k, X_transaction = None, X_cascade = None, nsamps = 1, mean_only = False, return_separate = False, **kwargs):\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     transaction_samps = self.dcmm.forecast_marginal(k, (X_transaction[0], X_transaction[1]), nsamps, mean_only)\n",
    "        # else:\n",
    "        #     transaction_samps = self.dcmm.forecast_marginal(k, (X_transaction, X_transaction), nsamps, mean_only)\n",
    "\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "\n",
    "        transaction_samps = self.dcmm.forecast_marginal(k, X_transaction, nsamps, mean_only)\n",
    "        cascade_samps = self.forecast_cascade(k, transaction_samps, X_cascade, nsamps, mean_only)\n",
    "        excess_samps = self.forecast_excess(cascade_samps[self.ncascade-1,:], nsamps, mean_only)\n",
    "\n",
    "        # Sometimes we may want to investigate the transaction, cascade, and excess samples separately\n",
    "        if return_separate:\n",
    "            return transaction_samps, cascade_samps, excess_samps\n",
    "\n",
    "        samps = np.r_[transaction_samps.reshape(1, -1), cascade_samps, excess_samps.reshape(1, -1)]\n",
    "        return np.sum(samps, axis = 0)\n",
    "\n",
    "    def forecast_marginal_lf_sample(self, k, X_transaction = None, X_cascade = None, phi_samps = None, nsamps = 1, mean_only = False, return_separate = False, **kwargs):\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     transaction_samps = self.dcmm.forecast_marginal_lf_sample(k, (X_transaction[0], X_transaction[1]),\n",
    "        #                                                                (phi_samps, phi_samps), nsamps, mean_only)\n",
    "        # else:\n",
    "        #     transaction_samps = self.dcmm.forecast_marginal_lf_sample(k, (X_transaction, X_transaction), (phi_samps, phi_samps), nsamps, mean_only)\n",
    "\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "        transaction_samps = self.dcmm.forecast_marginal_lf_sample(k, X_transaction,\n",
    "                                                                  (phi_samps, phi_samps), nsamps, mean_only)\n",
    "        cascade_samps = self.forecast_cascade(k, transaction_samps, X_cascade, nsamps, mean_only)\n",
    "        excess_samps = self.forecast_excess(cascade_samps[self.ncascade-1, :], nsamps, mean_only)\n",
    "\n",
    "        # Sometimes we may want to investigate the transaction, cascade, and excess samples separately\n",
    "        if return_separate:\n",
    "            return transaction_samps, cascade_samps, excess_samps\n",
    "\n",
    "        samps = np.r_[transaction_samps.reshape(1,-1), cascade_samps, excess_samps.reshape(1,-1)]\n",
    "        return np.sum(samps, axis=0)\n",
    "\n",
    "    def forecast_marginal_lf_analytic(self, k, X_transaction = None, X_cascade = None, phi_mu = None, phi_sigma = None, nsamps = 1, mean_only = False, return_separate=False, **kwargs):\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     transaction_samps = self.dcmm.forecast_marginal_lf_analytic(k, (X_transaction[0], X_transaction[1]),\n",
    "        #                                                                       (phi_mu, phi_mu), (phi_sigma, phi_sigma),\n",
    "        #                                                                       nsamps, mean_only)\n",
    "        # else:\n",
    "        #     transaction_samps = self.dcmm.forecast_marginal_lf_analytic(k, (X_transaction, X_transaction), (phi_mu, phi_mu), (phi_sigma, phi_sigma), nsamps, mean_only)\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "        # pm = self.make_pair(phi_mu)\n",
    "        # ps = self.make_pair(phi_sigma)\n",
    "\n",
    "        transaction_samps = self.dcmm.forecast_marginal_lf_analytic(k, X_transaction, phi_mu, phi_sigma, nsamps, mean_only)\n",
    "        cascade_samps = self.forecast_cascade(k, transaction_samps, X_cascade, nsamps, mean_only)\n",
    "        excess_samps = self.forecast_excess(cascade_samps[self.ncascade-1, :], nsamps, mean_only)\n",
    "\n",
    "        # Sometimes we may want to investigate the transaction, cascade, and excess samples separately\n",
    "        if return_separate:\n",
    "            return transaction_samps, cascade_samps, excess_samps\n",
    "\n",
    "        samps = np.r_[transaction_samps.reshape(1,-1), cascade_samps, excess_samps.reshape(1,-1)]\n",
    "        return np.sum(samps, axis=0)\n",
    "\n",
    "    def forecast_path(self, k, X_transaction = None, X_cascade = None, nsamps = 1, return_separate = False):\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     transaction_samps = self.dcmm.forecast_path(k, (X_transaction[0], X_transaction[1]), nsamps)\n",
    "        # else:\n",
    "        #     transaction_samps = self.dcmm.forecast_path(k, (X_transaction, X_transaction), nsamps)\n",
    "\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "\n",
    "        transaction_samps = self.dcmm.forecast_path(k, X_transaction, nsamps)\n",
    "        cascade_samps = np.array(\n",
    "            list(map(lambda h: self.forecast_cascade(h, transaction_samps[:, h], X_cascade[h], nsamps),\n",
    "                     range(k)))).T\n",
    "        excess_samps = np.array(list(map(lambda h: self.forecast_excess(cascade_samps[:, self.ncascade-1, h], nsamps),\n",
    "                     range(k)))).T\n",
    "\n",
    "        # Sometimes we may want to investigate the transaction, cascade, and excess samples separately\n",
    "        if return_separate:\n",
    "            return transaction_samps, cascade_samps, excess_samps\n",
    "\n",
    "\n",
    "        samps = np.concatenate((transaction_samps[:, None, :], cascade_samps, excess_samps), axis=1)\n",
    "        return np.sum(samps, axis=1)\n",
    "\n",
    "    def forecast_path_copula(self, k, X_transaction = None, X_cascade = None, nsamps = 1, return_separate = False, **kwargs):\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     transaction_samps = self.dcmm.forecast_path_copula(k, (X_transaction[0], X_transaction[1]), nsamps, **kwargs)\n",
    "        # else:\n",
    "        #     transaction_samps = self.dcmm.forecast_path_copula(k, (X_transaction, X_transaction), nsamps, **kwargs)\n",
    "\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "\n",
    "        transaction_samps = self.dcmm.forecast_path_copula(k, X_transaction, nsamps, **kwargs)\n",
    "        cascade_samps = np.array(\n",
    "            list(map(lambda h: self.forecast_cascade(h, transaction_samps[:, h], X_cascade[h], nsamps),\n",
    "                     range(k)))).T\n",
    "        excess_samps = np.array(list(map(lambda h: self.forecast_excess(cascade_samps[:, self.ncascade-1, h], nsamps),\n",
    "                                         range(k)))).T\n",
    "\n",
    "        # Sometimes we may want to investigate the transaction, cascade, and excess samples separately\n",
    "        if return_separate:\n",
    "            return transaction_samps, cascade_samps, excess_samps\n",
    "\n",
    "        samps = np.concatenate((transaction_samps[:, None, :], cascade_samps, excess_samps), axis=1)\n",
    "        return np.sum(samps, axis=1)\n",
    "    \n",
    "    def forecast_path_lf_copula(self, k, X_transaction = None, X_cascade = None, phi_mu = None, phi_sigma = None, phi_psi = None, nsamps = 1, return_separate = False, **kwargs):\n",
    "        # if isinstance(X_transaction, (list, tuple)):\n",
    "        #     transaction_samps = self.dcmm.forecast_path_lf_copula(k, (X_transaction[0], X_transaction[1]),\n",
    "        #                                                                   (phi_mu, phi_mu), (phi_sigma, phi_sigma),\n",
    "        #                                                                   (phi_psi, phi_psi), nsamps, **kwargs)\n",
    "        # else:\n",
    "        #     transaction_samps = self.dcmm.forecast_path_lf_copula(k, (X_transaction, X_transaction), (phi_mu, phi_mu), (phi_sigma, phi_sigma), (phi_psi, phi_psi), nsamps, **kwargs)\n",
    "\n",
    "        # X_t = self.make_pair(X_transaction)\n",
    "        # pm = self.make_pair(phi_mu)\n",
    "        # ps = self.make_pair(phi_sigma)\n",
    "        # pp = self.make_pair(phi_psi)\n",
    "\n",
    "        transaction_samps = self.dcmm.forecast_path_lf_copula(k, X_transaction, phi_mu, phi_sigma, phi_psi, nsamps, **kwargs)\n",
    "        cascade_samps = np.array(\n",
    "            list(map(lambda h: self.forecast_cascade(h, transaction_samps[:, h], X_cascade[h], nsamps),\n",
    "                     range(k)))).T\n",
    "        excess_samps = np.array(list(map(lambda h: self.forecast_excess(cascade_samps[:, self.ncascade-1, h], nsamps),\n",
    "                                         range(k)))).T\n",
    "\n",
    "        # Sometimes we may want to investigate the transaction, cascade, and excess samples separately\n",
    "        if return_separate:\n",
    "            return transaction_samps, cascade_samps, excess_samps\n",
    "\n",
    "        samps = np.concatenate((transaction_samps[:, None, :], cascade_samps, excess_samps), axis=1)\n",
    "        return np.sum(samps, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_dglm.ipynb.\n",
      "Converted 01_update.ipynb.\n",
      "Converted 02_forecast.ipynb.\n",
      "Converted 03_define_models.ipynb.\n",
      "Converted 04_seasonal.ipynb.\n",
      "Converted 05_analysis.ipynb.\n",
      "Converted 06_conjugates.ipynb.\n",
      "Converted 07_point_forecast.ipynb.\n",
      "Converted 08_loss_functions.ipynb.\n",
      "Converted 09_plot.ipynb.\n",
      "Converted 10_shared.ipynb.\n",
      "Converted 11_dcmm.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
